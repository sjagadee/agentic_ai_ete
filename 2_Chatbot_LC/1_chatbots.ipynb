{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d3f0a0",
   "metadata": {},
   "source": [
    "### Lets build chatbots using langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592d24ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517cb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2f42c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Srini. What brings you here today? Do you have any questions or topics you'd like to discuss?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 43, 'total_tokens': 71, 'completion_time': 0.03664214, 'completion_tokens_details': None, 'prompt_time': 0.00211933, 'prompt_tokens_details': None, 'queue_time': 0.005667805, 'total_time': 0.03876147}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9ca2574dca', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--21cb0172-2eb5-4e83-b588-99e23c1d3c83-0', usage_metadata={'input_tokens': 43, 'output_tokens': 28, 'total_tokens': 71})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets invoke the model\n",
    "model.invoke([HumanMessage(content=\"Hi, my name is srini!\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf40fa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about your name as our conversation has just started. I'm a large language model, I don't have the ability to retain information about individual users or recall previous conversations. Each time you interact with me, it's a new conversation. If you'd like to share your name with me, I'd be happy to chat with you!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 40, 'total_tokens': 114, 'completion_time': 0.093669409, 'completion_tokens_details': None, 'prompt_time': 0.001827275, 'prompt_tokens_details': None, 'queue_time': 0.005696141, 'total_time': 0.095496684}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4dea31877a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--0ecd352f-69cd-43cf-97ea-25d5d0e908bf-0', usage_metadata={'input_tokens': 40, 'output_tokens': 74, 'total_tokens': 114})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What is my name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26b8792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Srini.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 97, 'total_tokens': 104, 'completion_time': 0.009115773, 'completion_tokens_details': None, 'prompt_time': 0.005578157, 'prompt_tokens_details': None, 'queue_time': 0.005326363, 'total_time': 0.01469393}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9ca2574dca', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--bc9f76a7-c864-4aad-a778-e5cb7c1e55e4-0', usage_metadata={'input_tokens': 97, 'output_tokens': 7, 'total_tokens': 104})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets invoke the model\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is srini!\"),\n",
    "        AIMessage(content=\"Nice to meet you, Srini! I'm happy to chat with you. Is there something on your mind that you'd like to talk about, or do you just want to say hello?\"),\n",
    "        HumanMessage(content=\"What is my name?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247801b7",
   "metadata": {},
   "source": [
    "As we see here:\n",
    "- If we do not provide the context. LLM will not have any information\n",
    "- If we provide the context, it can easily know and answer based on context\n",
    "\n",
    "This is called illusion of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9e8f2",
   "metadata": {},
   "source": [
    "### Message History\n",
    "\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# history store\n",
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc1628bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to get the chat history based on session id\n",
    "\n",
    "def get_chat_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07568426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup config\n",
    "config = {'configurable': {'session_id': 'chat_1'}}\n",
    "\n",
    "# setup model with the session history\n",
    "with_chat_history = RunnableWithMessageHistory(model, get_session_history=get_chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1b84220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact with model with session history\n",
    "response = with_chat_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is srini! I am Senior GenAI Engineer!\"),\n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872e8de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems like you've repeated your introduction, Srini. Don't worry, I've got it noted! You're a Senior GenAI Engineer. What would you like to talk about? Would you like to discuss a specific AI-related topic, or do you have a question for me?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e8bcd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You still haven't told me your name. I'm happy to chat with you, but I don't know what to call you. If you'd like to share your name, I can try to recall it and use it in our conversation.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the config - new session id\n",
    "config1 = {'configurable': {'session_id': 'chat_2'}}\n",
    "\n",
    "# interact with model with session history\n",
    "response = with_chat_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, What is my name?\"),\n",
    "    ],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34c15fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Srini.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interact with model with session history - with the first session\n",
    "response = with_chat_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, What is my name?\"),\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d52c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
