{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377258e1",
   "metadata": {},
   "source": [
    "## Manage the conversion history\n",
    "\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04fe1213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srinivas/Documents/Others/My_projects/Python/DSAIML/agenticai/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage, trim_messages\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39530363",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a107a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history store\n",
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21a9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to get the chat history based on session id\n",
    "\n",
    "def get_chat_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7653a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup config\n",
    "config = {'configurable': {'session_id': 'chat_1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df0a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding more complexity to the chain\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all the question to the best of your ability in {language} Language.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd5fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(chain, get_session_history=get_chat_history, input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f587cb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते स्रीनि! मैं आपकी मदद करने के लिए तैयार हूँ। क्या आप किसी विशिष्ट विषय या समस्या पर चर्चा करना चाहते हैं?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Hi, My name is srini!\"),\n",
    "        ],\n",
    "        \"language\": \"Hindi\",\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3560505c",
   "metadata": {},
   "source": [
    "Let us setup `trim_messages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b4e34b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c6b6634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daa1757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# lets build a chain\n",
    "chain = RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer) | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ff40bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about your preferences. You haven't mentioned it before, so I'm not sure which ice cream you like. If you'd like to share, I'd be happy to chat about it!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 114, 'total_tokens': 159, 'completion_time': 0.066053254, 'completion_tokens_details': None, 'prompt_time': 0.007197251, 'prompt_tokens_details': None, 'queue_time': 0.005520229, 'total_time': 0.073250505}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9ca2574dca', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--42e8f89c-ad15-496a-ab83-222c24709602-0', usage_metadata={'input_tokens': 114, 'output_tokens': 45, 'total_tokens': 159})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"Which ice cream do I like?\")], \n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92db35d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked me a simple math problem: 2 + 2.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 117, 'total_tokens': 132, 'completion_time': 0.019149302, 'completion_tokens_details': None, 'prompt_time': 0.006373331, 'prompt_tokens_details': None, 'queue_time': 0.005516247, 'total_time': 0.025522633}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4dea31877a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--1eed44db-f5b4-4711-9063-de5efcacaec9-0', usage_metadata={'input_tokens': 117, 'output_tokens': 15, 'total_tokens': 132})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What is the math problem, did I ask?\")], \n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37a9c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets wrap in with message history\n",
    "\n",
    "chain_with_history_v3 = RunnableWithMessageHistory(chain, get_session_history=get_chat_history, input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad773a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {'configurable': {'session_id': 'chat_2'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77515392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't know your name. You haven't told me yet.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 112, 'total_tokens': 127, 'completion_time': 0.028131973, 'completion_tokens_details': None, 'prompt_time': 0.006053253, 'prompt_tokens_details': None, 'queue_time': 0.005164167, 'total_time': 0.034185226}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4dea31877a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--4d9994e7-5220-409d-8804-5a8d2c33fab3-0', usage_metadata={'input_tokens': 112, 'output_tokens': 15, 'total_tokens': 127})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history_v3.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What is my name?\")], \n",
    "        \"language\": \"English\"\n",
    "    },\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04c76591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked me for the result of the math problem \"2 + 2\".', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 117, 'total_tokens': 134, 'completion_time': 0.020218324, 'completion_tokens_details': None, 'prompt_time': 0.006469782, 'prompt_tokens_details': None, 'queue_time': 0.005558881, 'total_time': 0.026688106}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4dea31877a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--048ce99e-5556-4946-8002-7ec75497e160-0', usage_metadata={'input_tokens': 117, 'output_tokens': 17, 'total_tokens': 134})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history_v3.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What is the math problem, did I ask?\")], \n",
    "        \"language\": \"English\"\n",
    "    },\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "571230e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm a large language model, I don't have any information about your personal preferences. We just started our conversation, and I don't have any knowledge about your likes or dislikes. Would you like to share what kind of ice cream you like?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 114, 'total_tokens': 165, 'completion_time': 0.072506609, 'completion_tokens_details': None, 'prompt_time': 0.006159653, 'prompt_tokens_details': None, 'queue_time': 0.005163103, 'total_time': 0.078666262}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4dea31877a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ab862813-966a-4e2a-9485-17f2041a51b2-0', usage_metadata={'input_tokens': 114, 'output_tokens': 51, 'total_tokens': 165})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history_v3.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"Which ice cream do I like?\")], \n",
    "        \"language\": \"English\"\n",
    "    },\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a161882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
