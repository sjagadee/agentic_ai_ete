{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3185b8c0",
   "metadata": {},
   "source": [
    "### Agentic RAG\n",
    "\n",
    "Here is the workflow for current implementation\n",
    "\n",
    "- Use two vector db's \n",
    "    - first db will have LangGraph related blogs\n",
    "    - second db will have LangChain related blogs\n",
    "- An Agent (Agent 1) will decide based on the user query to choose first db or second db\n",
    "- Once the related documents are fetched, we check if the documents have correct information\n",
    "    - If the information is selected document context is not appropriate\n",
    "    - Rewrite (Agent 2) the query and send the updated query back to the agent\n",
    "- If the info is correct - pass it as contect to the Generator (Agent 3) and finally output the response\n",
    "- If an unrelated query is asked agent (Agent 1) will directly reject and appropriate answer will be sent as output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af56c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.embeddings import init_embeddings\n",
    "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.tools import create_retriever_tool \n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from typing import Annotated, TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import operator\n",
    "import requests\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1275f8",
   "metadata": {},
   "source": [
    "### Model and Embedding initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0fc875",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\n",
    "    model=\"qwen/qwen3-32b\",  # or any other Groq model\n",
    "    model_provider=\"groq\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "embeddings = init_embeddings(\"openai:text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9769c2",
   "metadata": {},
   "source": [
    "### Load, extract and flatten documents from Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e84ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load and extract docs from LangGraph docs\n",
    "\n",
    "urls_lg = [\n",
    "    \"https://docs.langchain.com/oss/python/langgraph/quickstart\",\n",
    "    \"https://docs.langchain.com/oss/python/langgraph/workflows-agents\",\n",
    "    \"https://docs.langchain.com/oss/python/langgraph/use-graph-api#map-reduce-and-the-send-api\"\n",
    "]\n",
    "\n",
    "# load the docs from the urls \n",
    "docs_lg = [WebBaseLoader(url).load() for url in urls_lg]\n",
    "docs_lg\n",
    "\n",
    "# extract the inner list from docs and flatten it \n",
    "flat_doc_list_lg = [doc for sublist in docs_lg for doc in sublist]\n",
    "flat_doc_list_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78854ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load and extract docs from LangGraph docs\n",
    "\n",
    "urls_lc = [\n",
    "    \"https://docs.langchain.com/oss/python/langchain/overview\",\n",
    "    \"https://docs.langchain.com/oss/python/langchain/agents\",\n",
    "    \"https://docs.langchain.com/oss/python/langchain/guardrails\"\n",
    "]\n",
    "\n",
    "# load the docs from the urls \n",
    "docs_lc = [WebBaseLoader(url).load() for url in urls_lc]\n",
    "docs_lc\n",
    "\n",
    "# extract the inner list from docs and flatten it \n",
    "flat_docs_list_lc = [doc for sublist in docs_lc for doc in sublist]\n",
    "flat_docs_list_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ed9b6",
   "metadata": {},
   "source": [
    "### Text Splitter, Document Store (Vector Store) and Retriever (Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f182029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up text splitter - recursive character based with chunk size of 1000 and chunk overlap of 100\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fcc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_chunks_lg = text_splitter.split_documents(flat_doc_list_lg)\n",
    "doc_chunks_lg\n",
    "\n",
    "vectorstore_faiss = FAISS.from_documents(doc_chunks_lg, embeddings)\n",
    "retriever_lg = vectorstore_faiss.as_retriever()\n",
    "\n",
    "print(retriever_lg.invoke(\"How to build agents?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63770616",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lc_chunks = text_splitter.split_documents(flat_docs_list_lc)\n",
    "doc_lc_chunks\n",
    "\n",
    "vectorstore_chroma = Chroma.from_documents(doc_lc_chunks, embeddings)\n",
    "retriever_lc = vectorstore_chroma.as_retriever()\n",
    "\n",
    "print(retriever_lc.invoke(\"How to build chains?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba2320",
   "metadata": {},
   "source": [
    "### Setup Retriever as a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6086c762",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_langgraph_tool = create_retriever_tool(\n",
    "    retriever=retriever_lg,\n",
    "    name=\"retriever_lg_vector_db_blog\",\n",
    "    description=\"Search and extract information about LangGraph\",\n",
    ")\n",
    "\n",
    "retriever_langchain_tool = create_retriever_tool(\n",
    "    retriever=retriever_lc,\n",
    "    name=\"retriever_lc_vector_db_blog\",\n",
    "    description=\"Search and extract information about LangChain\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c1b3c",
   "metadata": {},
   "source": [
    "### Status Till Now:\n",
    "\n",
    "- Extracted documents from web about LangGraph\n",
    "- It has information about LangGraph Implementation\n",
    "- Used FAISS vectorstore to save the document and chunking them\n",
    "- Created vectorstore as retriever\n",
    "- Created retriever tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248297f6",
   "metadata": {},
   "source": [
    "### Combine tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53eca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_langgraph_tool, retriever_langchain_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280df788",
   "metadata": {},
   "source": [
    "### Bind the Model with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb2357",
   "metadata": {},
   "source": [
    "### Build Graph\n",
    "\n",
    "Step 1: Create an Agent that will use model with tools to get relavent documents based on query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2af6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    # add_messages is a reducer function, that defines how to add messages to the list\n",
    "    # by default state would replace the entry, but with add_messages it would append to the list\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b185145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    Invokes the agent model to generate a response based on current state. Given the\n",
    "    question, it will decide to call the retriever tool or end the call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke({\"messages\": messages})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83404a69",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947eb18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
